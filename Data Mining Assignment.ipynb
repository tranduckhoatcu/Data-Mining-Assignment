{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the relevant Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as ss\n",
    "from bs4 import BeautifulSoup\n",
    "import ast\n",
    "from urllib.request import Request, urlopen\n",
    "from itertools import combinations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get header from .name file and add to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('house-votes-84.data',header=None)\n",
    "soup_link2 = BeautifulSoup(open('house-votes-84.names'))\n",
    "table_header = soup_link2.find('p')\n",
    "\n",
    "def before(value, a):\n",
    "    pos_a = value.find(a)\n",
    "    if pos_a == -1: return \"\"\n",
    "    return value[0:pos_a]\n",
    "\n",
    "def after(value, a):\n",
    "    pos_a = value.rfind(a)\n",
    "    if pos_a == -1: return \"\"\n",
    "    adjusted_pos_a = pos_a + len(a)\n",
    "    if adjusted_pos_a >= len(value): return \"\"\n",
    "    return value[adjusted_pos_a:]\n",
    "\n",
    "header = after(table_header.text,\"7. Attribute Information:\\n\")\n",
    "header = before(header,\"\\n8. Missing Attribute Values: Denoted by\")\n",
    "list_header = []\n",
    "for i in range(header.count('\\n')):\n",
    "    if(i<10):\n",
    "        buffer = after(header,\" \"+str(i+1)+\". \")\n",
    "    else:\n",
    "        buffer = after(header,str(i+1)+\". \")\n",
    "    buffer = before(buffer,\":\")\n",
    "    list_header.append(str(buffer))\n",
    "\n",
    "dataset.columns = list_header\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### There are 434 rows and 17 columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset.describe(include = 'object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the table above, we can see the basic data structure of dataset: \n",
    "#### All columns is categorical data\n",
    "#### First column \"republican\" have 2 unique value which is (republican and democrat)\n",
    "#### 16 other columns have 3 unique value which are y, n and ? (while ? is the missing value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing values is fill with \"?\" in the dataset so we have to take care of it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## replace \"?\" value to most frequent values in each columns\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values = \"?\" , strategy = 'most_frequent',verbose=0)\n",
    "imputer = imputer.fit(dataset.iloc[:,1:])\n",
    "dataset.iloc[:, 1:] = imputer.transform(dataset.iloc[:, 1:])\n",
    "display(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So that all the missing value is fill with the most frequent values\n",
    "#### Because there only 2 unique values for all columns so we don't need dummy variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Correlation Matrix of dataset to check correlations among columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Because all columns of the dataset have categorical values so that we’re can not simply use corr() function of Pandas dataframe. we're looking for other measure of association between two categorical features.\n",
    "#### By using Cramér’s V correlation which based on a nominal variation of Pearson’s Chi-Square Test will help us to handle this scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cramers_v(confusion_matrix):\n",
    "    chi2 = ss.chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum().sum()\n",
    "    phi2 = chi2/n\n",
    "    r,k = confusion_matrix.shape\n",
    "    phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))    \n",
    "    rcorr = r - ((r-1)**2)/(n-1)\n",
    "    kcorr = k - ((k-1)**2)/(n-1)\n",
    "    return np.sqrt(phi2corr / min( (kcorr-1), (rcorr-1)))\n",
    "\n",
    "cols = list(dataset.columns)\n",
    "corrM = np.zeros((len(cols),len(cols)))\n",
    "for col1, col2 in combinations(cols, 2):\n",
    "    idx1, idx2 = cols.index(col1), cols.index(col2)\n",
    "    corrM[idx1, idx2] = cramers_v(pd.crosstab(dataset[col1], dataset[col2]))\n",
    "    corrM[idx2, idx1] = corrM[idx1, idx2]\n",
    "\n",
    "corr = pd.DataFrame(corrM, index=cols, columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Correlation Matrix of dataset by heat map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=2)\n",
    "fig, ax = plt.subplots(figsize=(30, 30))\n",
    "ax = sns.heatmap(corr, annot=True, ax=ax); ax.set_title(\"Cramer V Correlation between Variables\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting features based on correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We compare the correlation between features and remove one of two features that have a correlation higher than 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = np.full((corr.shape[0],), True, dtype=bool)\n",
    "for i in range(corr.shape[0]):\n",
    "    for j in range(i+1, corr.shape[0]):\n",
    "        if corr.iloc[i,j] >= 0.9:\n",
    "            if columns[j]:\n",
    "                columns[j] = False\n",
    "                selected_columns = dataset.columns[columns]\n",
    "                new_dataset = dataset[selected_columns]\n",
    "remove_columns = (list(set(dataset.columns) - set(new_dataset.columns)))\n",
    "print(str(len(remove_columns))+\" column removed which is: \"+str(remove_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now dataset has only those columns with correlation less than 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(new_dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate distribution of selected features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We create new distribution dataframe for calculating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = pd.crosstab(index = new_dataset[\"Class Name\"],columns=new_dataset[\"handicapped-infants\"])\n",
    "buffer = buffer.stack()\n",
    "buffer.index = ['_'.join(idx) for idx in buffer.index]\n",
    "buffer.name = \"handicapped-infants\"\n",
    "distribution = pd.DataFrame(buffer)\n",
    "for col in new_dataset.columns:\n",
    "    if (col == \"Class Name\") or (col == \"handicapped-infants\"):\n",
    "        pass\n",
    "    else:\n",
    "        buffer = pd.crosstab(index = new_dataset[\"Class Name\"],columns=new_dataset[col])\n",
    "        buffer = buffer.stack()\n",
    "        buffer.index = ['_'.join(idx) for idx in buffer.index]\n",
    "        distribution[col] = buffer.values \n",
    "display(distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the data to visualize their distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using stacked bar to plot distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "distribution.T.plot(kind='bar', stacked=True,figsize=(20,8),label='big')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "# Import here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "oe = LabelEncoder()\n",
    "training_dataset = dataset.copy()\n",
    "dataset_features = training_dataset.drop(columns='Class Name')\n",
    "dataset_classname = training_dataset['Class Name']\n",
    "X = dataset_features.copy()\n",
    "for col in X:\n",
    "    X[col] = oe.fit_transform(X[col])\n",
    "Y = lb.fit_transform(dataset_classname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree C4.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to apply Decision Tree C4.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take 20 random records of our dataset to perform the Decision Tree C4.5 Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Class Name | handicapped-infants | water-project-cost-sharing | adoption-of-the-budget-resolution | physician-fee-freeze | el-salvador-aid | religious-groups-in-schools | anti-satellite-test-ban | aid-to-nicaraguan-contras | mx-missile | immigration | synfuels-corporation-cutback | education-spending | superfund-right-to-sue | crime | duty-free-exports | export-administration-act-south-africa |\n",
    "| ---------- | ------------------- | -------------------------- | --------------------------------- | -------------------- | --------------- | --------------------------- | ----------------------- | ------------------------- | ---------- | ----------- | ---------------------------- | ------------------ | ---------------------- | ----- | ----------------- | -------------------------------------- |\n",
    "| democrat   | n                   | y                          | y                                 | n                    | y               | y                           | n                       | n                         | n          | n           | y                            | n                  | y                      | y     | n                 | n                                      |\n",
    "| democrat   | n                   | y                          | y                                 | n                    | y               | y                           | n                       | n                         | n          | n           | y                            | n                  | y                      | n     | n                 | y                                      |\n",
    "| democrat   | n                   | y                          | y                                 | n                    | y               | y                           | n                       | n                         | n          | n           | n                            | n                  | y                      | y     | y                 | y                                      |\n",
    "| democrat   | n                   | y                          | n                                 | y                    | y               | y                           | n                       | n                         | n          | n           | n                            | n                  | y                      | y     | y                 | y                                      |\n",
    "| democrat   | n                   | y                          | y                                 | n                    | n               | n                           | y                       | y                         | y          | n           | n                            | n                  | y                      | n     | n                 | y                                      |\n",
    "| democrat   | y                   | y                          | y                                 | n                    | y               | y                           | n                       | n                         | n          | n           | y                            | n                  | y                      | y     | y                 | y                                      |\n",
    "| democrat   | y                   | y                          | y                                 | n                    | n               | n                           | y                       | y                         | y          | n           | n                            | n                  | n                      | n     | n                 | y                                      |\n",
    "| democrat   | y                   | y                          | y                                 | n                    | n               | y                           | y                       | y                         | y          | y           | y                            | n                  | n                      | n     | y                 | y                                      |\n",
    "| democrat   | y                   | n                          | y                                 | n                    | n               | y                           | n                       | y                         | y          | y           | y                            | y                  | y                      | n     | n                 | y                                      |\n",
    "| democrat   | y                   | y                          | y                                 | n                    | n               | n                           | y                       | y                         | y          | n           | n                            | n                  | y                      | n     | y                 | y                                      |\n",
    "| democrat   | y                   | y                          | y                                 | n                    | n               | n                           | y                       | y                         | y          | n           | y                            | n                  | n                      | n     | y                 | y                                      |\n",
    "| republican | n                   | y                          | n                                 | y                    | y               | y                           | n                       | n                         | n          | y           | n                            | y                  | y                      | y     | n                 | y                                      |\n",
    "| republican | n                   | y                          | n                                 | y                    | y               | y                           | n                       | n                         | n          | n           | n                            | y                  | y                      | y     | n                 | y                                      |\n",
    "| republican | n                   | y                          | n                                 | y                    | y               | y                           | n                       | n                         | n          | n           | n                            | n                  | y                      | y     | n                 | y                                      |\n",
    "| republican | n                   | y                          | n                                 | y                    | y               | y                           | n                       | n                         | n          | n           | n                            | y                  | y                      | y     | n                 | y                                      |\n",
    "| republican | n                   | y                          | n                                 | y                    | y               | n                           | n                       | n                         | n          | n           | n                            | n                  | y                      | y     | n                 | n                                      |\n",
    "| republican | n                   | y                          | n                                 | y                    | y               | y                           | n                       | n                         | n          | n           | y                            | n                  | y                      | y     | n                 | y                                      |\n",
    "| republican | n                   | y                          | n                                 | y                    | y               | y                           | n                       | n                         | n          | n           | n                            | y                  | y                      | y     | n                 | y                                      |\n",
    "| republican | n                   | y                          | n                                 | y                    | y               | y                           | n                       | n                         | n          | y           | n                            | y                  | y                      | y     | n                 | y                                      |\n",
    "| republican | n                   | y                          | n                                 | y                    | y               | y                           | n                       | n                         | n          | n           | n                            | n                  | y                      | y     | n                 | n                                      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step, we need to calculate the Expected information (entropy) of \"Class Name\":\n",
    "\n",
    "To do that we need to find out the probability of each class in \"Class Name\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|| Repulican | Democrat|\n",
    "| :---- |:----:| :----:|\n",
    "| Occurrence| 9 | 11 |\n",
    "| Probability | 0.45 | 0.55 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can calculate the **entropy** of \"Class Name\":"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "Info(Class Name) = \\sum_{i=1}^m p_i log_2 (p_i) = -0.45 * log_2 0.45 - 0.55 * log_2 0.55 = 0.99\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select the root node, we need to calculate the Gain Ratio of all attributes\n",
    "\n",
    "Let's take the \"handicapped-infants\" for an example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Class Name | handicapped-infants |\n",
    "| ---------- | ------------------- |\n",
    "| democrat   | n                   |\n",
    "| democrat   | n                   |\n",
    "| democrat   | n                   |\n",
    "| democrat   | n                   |\n",
    "| democrat   | n                   |\n",
    "| democrat   | y                   |\n",
    "| democrat   | y                   |\n",
    "| democrat   | y                   |\n",
    "| democrat   | y                   |\n",
    "| democrat   | y                   |\n",
    "| democrat   | y                   |\n",
    "| republican | n                   |\n",
    "| republican | n                   |\n",
    "| republican | n                   |\n",
    "| republican | n                   |\n",
    "| republican | n                   |\n",
    "| republican | n                   |\n",
    "| republican | n                   |\n",
    "| republican | n                   |\n",
    "| republican | n                   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to find the occurences of each attribute values and its information needed (after using \"handicapped-infants\" to split \"Class Name\") for each class:\n",
    "\n",
    "| handicapped-infants | republican (R) | democrat (D) | I(R, D) |\n",
    "| :-----------------: | :------------: | :----------: | :------ |\n",
    "| yes                 | 0              | 6            | \\begin{equation*} -\\frac{0}{6} log_2 \\frac{0}{6} -\\frac{6}{6} log_2 \\frac{6}{6} = 0 \\end{equation*}|\n",
    "| no                  | 9              | 5            | \\begin{equation*} -\\frac{9}{14} log_2 \\frac{9}{14} -\\frac{9}{14} log_2 \\frac{9}{14} = 0.94 \\end{equation*}|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information needed of handicapped-infants is\n",
    "$$\n",
    "Info (handicapped-infants) = \\frac {6}{20} * 0 + \\frac {14}{20} * 0.94 = 0.66 \n",
    "$$\n",
    "\n",
    "Then we calculate the Information gained of handicapped-infants:\n",
    "\n",
    "$$\n",
    "Gain (handicapped-infants) = Entropy(0.45, 0.64) - Info(handicapped-infants) = 0.99 - 0.66 = 0.33\n",
    "$$\n",
    "\n",
    "Split Information of handicapped-infants:\n",
    "\n",
    "$$\n",
    "Split (handicapped-infants) = -\\frac{6}{20} log_2 \\frac{6}{20} -\\frac{14}{20} log_2 \\frac{14}{20} = 0.88\n",
    "$$\n",
    "\n",
    "Finally, we can compute the Gain Ratio of handicapped-infants:\n",
    "\n",
    "$$\n",
    "Gain_Ratio (handicapped-infants) = \\frac {Gain_info (handicapped-infants)} {Split (handicapped-infants)} = \\frac {0.33}{0.88} = 0.38\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do it continuosly for all others attributes, we have:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                    | handicapped-infants | water-project-cost-sharing | adoption-of-the-budget-resolution | physician-fee-freeze | el-salvador-aid | religious-groups-in-schools | anti-satellite-test-ban | aid-to-nicaraguan-contras | mx-missile | immigration | synfuels-corporation-cutback | education-spending | superfund-right-to-sue | crime | duty-free-exports | export-administration-act-south-africa |\n",
    "| ------------------ | ------------------- | -------------------------- | --------------------------------- | -------------------- | --------------- | --------------------------- | ----------------------- | ------------------------- | ---------- | ----------- | ---------------------------- | ------------------ | ---------------------- | ----- | ----------------- | -------------------------------------- |\n",
    "| I(R, D)yes         | 0.00                | 1.00                       | 0.00                              | 0.47                 | 0.94            | 1.00                        | 0.00                    | 0.00                      | 0.00       | 1.00        | 0.59                         | 0.65               | 1.00                   | 0.89  | 0.00              | 0.98                                   |\n",
    "| I(R, D)no          | 0.94                | 0.00                       | 0.47                              | 0.00                 | 0.00            | 0.72                        | 0.97                    | 0.94                      | 0.94       | 0.99        | 0.96                         | 0.86               | 0.00                   | 0.00  | 0.94              | 0.92                                   |\n",
    "| Information Needed | 0.66                | 0.95                       | 0.23                              | 0.23                 | 0.66            | 0.93                        | 0.73                    | 0.66                      | 0.66       | 0.99        | 0.83                         | 0.80               | 0.85                   | 0.58  | 0.66              | 0.97                                   |\n",
    "| Information gained | 0.33                | 0.04                       | 0.76                              | 0.76                 | 0.33            | 0.06                        | 0.26                    | 0.33                      | 0.33       | 0.00        | 0.16                         | 0.19               | 0.14                   | 0.41  | 0.33              | 0.02                                   |\n",
    "| Split Information  | 0.88                | 0.29                       | 1.00                              | 1.00                 | 0.88            | 0.81                        | 0.81                    | 0.88                      | 0.88       | 0.72        | 0.93                         | 0.88               | 0.61                   | 0.93  | 0.88              | 0.61                                   |\n",
    "| Gain Ratio         | 0.38                | 0.16                       | 0.76                              | 0.76                 | 0.38            | 0.08                        | 0.33                    | 0.38                      | 0.38       | 0.00        | 0.17                         | 0.22               | 0.24                   | 0.44  | 0.38              | 0.04                                   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attribute with the maximum gain ratio (adoption-of-the-budget-resolution) is selected as the splitting attribute.\n",
    "\n",
    "The root node now declared and split into 2 branchs (yes, no), for each branch, we redo above step to find the next node and keep going."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from graphviz import Source\n",
    "\n",
    "dtModel = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "dtModel.fit(X, Y)\n",
    "\n",
    "tree = export_graphviz(dtModel, out_file=None, label='root', feature_names=dataset_features.columns, class_names=lb.classes_, proportion=True, filled=True)\n",
    "s = Source(tree, format=\"png\")\n",
    "s.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(dtModel, X, Y, cv=10, scoring=\"f1\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes classifier can be found in sklearn.naive_bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nbModel = GaussianNB()\n",
    "cross_val_score(nbModel, X, Y, cv=10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZeroR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In ZeroR, the algorithm finds most frequent class name and return that prediction constantly   \n",
    "Because the dataset has 267 'democrat' records and 168 'republican' records  \n",
    "The accuracy of this ZeroR model should be **Acc = (267)/(267+168) ≈ 0.6138**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZeroR classifier (DummyClassifier) can be found in sklearn.dummy packages\n",
    "from sklearn.dummy import DummyClassifier\n",
    "zeroRModel = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "zeroRModel.fit(X, dataset_classname)\n",
    "print(\"ZeroR accuracy:\", zeroRModel.score(X, dataset_classname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "def calc_precision_recall_f1(model, x, y, K=10):\n",
    "    skf = KFold(n_splits=K, shuffle=True)\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    for train_index, test_index in skf.split(x, y):\n",
    "        X_train, X_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        \n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        f1_scores.append(f1)\n",
    "    \n",
    "    return precision_scores, recall_scores, f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,f1 = calc_precision_recall_f1(dtModel, X, dataset_classname)    #Precicion and Recall for Naive Bayes Classfier\n",
    "np.mean(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
